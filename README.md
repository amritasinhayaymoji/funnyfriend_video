# Funny Friend (Video Prototype) ğŸ¥

*Facial Emotion â†’ AI Chat â†’ Smart Device Control*
**Future Vision of the Funny Friend Project**

This is a backend-only prototype of Funny Friend â€” a smart AI assistant that reads your emotions through webcam, chats with you using LLM, and controls devices like lights and fans.
Itâ€™s designed as a **future version** of the main web app (Funny Friend Web), with no frontend â€” only webcam + voice + backend magic.

> ğŸ“ This is not part of the Google Developer Challenge submission, but is featured in the YouTube demo as a **"whatâ€™s next"** showcase.

---

## ğŸ¯ What It Can Do

| Feature                           | Description                                                           |
| --------------------------------- | --------------------------------------------------------------------- |
| ğŸ‘€ Facial Emotion Detection       | Detects your mood in real-time using webcam and DeepFace              |
| ğŸ§  Emotion-Aware AI Chat          | Starts conversation using OpenRouter LLM, based on your detected mood |
| ğŸ’¡ Smart Device Control           | Controls light/fan via Flask API routes (simulated IoT control)       |
| ğŸ–¥ï¸ Voice Interaction in Terminal | Uses mic input + speech output â€” no browser required                  |
| ğŸ”— Linked in Demo Video           | Shown inside the YouTube demo of the main Funny Friend web app        |

---

## ğŸ›  How to Run (Two-Terminal Setup)

> âœ… Requirements: Python 3.8+, webcam, microphone, internet

### ğŸ”¹ Step 1: Clone and Install

```bash
git clone https://github.com/yourusername/funny_friend-video.git
cd funny_friend-video
pip install -r requirements.txt
```

### ğŸ–¥ï¸ Terminal 1: Start Flask Backend (Device Control)

This will run the backend Flask server on port 5500.

```bash
python app.py
# Server will run at: http://localhost:5500
```

### ğŸ§  Terminal 2: Run Voice Assistant (Emotion + LLM)

This starts the voice assistant loop â€” it listens, detects emotion from your face, and replies via LLM.

```bash
python assistant.py
```

### ğŸ¤ Just speak naturally. The assistant will:

* Detect your facial emotion from webcam
* Decide how to respond (chat or device control)
* Speak the response using TTS

---

## ğŸ”§ Tech Stack

* **Python (Flask)** â€“ Backend for API and device control
* **DeepFace** â€“ Webcam-based facial emotion detection
* **SpeechRecognition + Pyttsx3** â€“ Voice input/output via terminal
* **OpenRouter API** â€“ Large Language Model for conversations
* **Custom APIs** â€“ Fan and Light control routes (`/device_control`)
* **No Frontend** â€“ All backend & terminal driven
* **Port** â€“ App runs on `http://localhost:5500`

---

## ğŸ” Ideal Use Cases

This backend version is designed for:

* Smart mirrors or wall displays
* Raspberry Pi setups
* Kiosk assistants
* Emotion-aware embedded systems
* Mental health or wellness bots

---

## ğŸ“¹ Demo & Context

This project is shown in the YouTube demo of our official competition submission:

* ğŸ”— **Main Project**: Funny Friend Web
* ğŸ“º **Watch Full Demo Video**: YouTube Link

---

## ğŸ“ For Judges

This repo is not submitted in the official Google Home API Developer Challenge.
Itâ€™s shown in the demo video to highlight the next-level potential of the Funny Friend assistant â€” moving beyond browser into real-world smart interfaces.
ğŸŒ Browser-based implementation was not used in this prototype to allow deeper system-level integration (e.g., webcam, real-time device control). This backend-first 
  approach enabled smoother testing of AI and hardware workflows beyond browser limits.
We hope it offers a glimpse into the future direction of emotional AI assistants.

---

## ğŸ‘©â€ğŸ’» Created By

**Funny Friend Project Series**
By \[Your Name]
ğŸ”— GitHub: [https://github.com/yourusername](https://github.com/yourusername)
ğŸ“§ Email: [yourname@email.com](mailto:yourname@email.com)

Built with â¤ï¸ to imagine AI that truly understands and responds to how we feel.